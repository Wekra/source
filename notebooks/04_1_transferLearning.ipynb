{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Lite and transfer learning\n",
    "\n",
    "Implement all the ToDos.\n",
    "\n",
    "You are working with the [Mendeley](https://data.mendeley.com/datasets/yz4v8tb3tp/5) dataset, which is modified version of the [LFWcrop](http://conradsanderson.id.au/lfwcrop/) dataset. The data is divided into two classes `smiling` and `non-smiling`. The samples for each class are located in a folder named after the class. There are aroung 600 images in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import collections\n",
    "import h5py\n",
    "import pathlib \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: load the data from disk. Be sure to keep the images associated to their class (folder name)\n",
    "def loadDataset(directory):\n",
    "    # keep link between images and labels (folder names). Use for example OrderedDict\n",
    "    result = collections.OrderedDict()\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadDataset(\"resources/dataset/\")\n",
    "\n",
    "# ToDo: split the dataset into subsets for training and testing.\n",
    "X_train = \n",
    "X_test = \n",
    "\n",
    "\n",
    "y_train =                  \n",
    "y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 97, 97, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 48, 48, 32)   864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalizationV1) (None, 48, 48, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 48, 48, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 48, 48, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 48, 48, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 48, 48, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 48, 48, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 48, 48, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 48, 48, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 48, 48, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 48, 48, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 49, 49, 96)   0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 24, 24, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 24, 24, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 24, 24, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 24, 24, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 24, 24, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 24, 24, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 24, 24, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 24, 24, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 24, 24, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 24, 24, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 24, 24, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 24, 24, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 24, 24, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 24, 24, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 24, 24, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 24, 24, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 24, 24, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 25, 25, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 12, 12, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 12, 12, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 12, 12, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 12, 12, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 12, 12, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 12, 12, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 12, 12, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 12, 12, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 12, 12, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 12, 12, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 12, 12, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 12, 12, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 12, 12, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 12, 12, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 12, 12, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 12, 12, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 12, 12, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 12, 12, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 12, 12, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 12, 12, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 12, 12, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 12, 12, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 12, 12, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 12, 12, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 12, 12, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 12, 12, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 13, 13, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 6, 6, 192)    1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 6, 6, 192)    768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 6, 6, 192)    0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 6, 6, 64)     12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 6, 6, 64)     256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 6, 6, 384)    24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 6, 6, 384)    1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 6, 6, 384)    0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 6, 6, 384)    3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 6, 6, 384)    1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 6, 6, 384)    0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 6, 6, 64)     24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 6, 6, 64)     256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 6, 6, 64)     0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 6, 6, 384)    24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 6, 6, 384)    1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 6, 6, 384)    0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 6, 6, 384)    3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 6, 6, 384)    1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 6, 6, 384)    0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 6, 6, 64)     24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 6, 6, 64)     256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 6, 6, 64)     0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 6, 6, 384)    24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 6, 6, 384)    1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 6, 6, 384)    0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 6, 6, 384)    3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 6, 6, 384)    1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 6, 6, 384)    0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 6, 6, 64)     24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 6, 6, 64)     256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 6, 6, 64)     0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 6, 6, 384)    24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 6, 6, 384)    1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 6, 6, 384)    0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 6, 6, 384)    3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 6, 6, 384)    1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 6, 6, 384)    0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 6, 6, 96)     36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 6, 6, 96)     384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 6, 6, 576)    55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 6, 6, 576)    2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 6, 6, 576)    0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 6, 6, 576)    5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 6, 6, 576)    2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 6, 6, 576)    0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 6, 6, 96)     55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 6, 6, 96)     384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 6, 6, 96)     0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 6, 6, 576)    55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 6, 6, 576)    2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 6, 6, 576)    0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 6, 6, 576)    5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 6, 6, 576)    2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 6, 6, 576)    0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 6, 6, 96)     55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 6, 6, 96)     384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 6, 6, 96)     0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 6, 6, 576)    55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 6, 6, 576)    2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 6, 6, 576)    0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 7, 7, 576)    0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 3, 3, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 3, 3, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 3, 3, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 3, 3, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 3, 3, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 3, 3, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 3, 3, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 3, 3, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 3, 3, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 3, 3, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 3, 3, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 3, 3, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 3, 3, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 3, 3, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 3, 3, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 3, 3, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 3, 3, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 3, 3, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 3, 3, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 3, 3, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 3, 3, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 3, 3, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 3, 3, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 3, 3, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 3, 3, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 3, 3, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 3, 3, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 3, 3, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 3, 3, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 3, 3, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 3, 3, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 3, 3, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalizationV1 (None, 3, 3, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 3, 3, 1280)   0           Conv_1_bn[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ToDo: Load a pretrained Network using keras. Choose from https://keras.io/applications/\n",
    "# ALTERNATIVELY: Define your own network using the keras sequential API: https://keras.io/getting-started/sequential-model-guide/\n",
    "base_model = \n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Append new output layers to the loaded model using the keras sequential API: https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  ...\n",
    "])\n",
    "\n",
    "model.compile(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo define training checkpointing\n",
    "\n",
    "checkpoint_path = \n",
    "checkpoint_dir = \n",
    "\n",
    "# ToDo: create checkpoint callback\n",
    "cp_callback ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 5s 166ms/step - loss: 0.9399 - acc: 0.5100\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 0.8584 - acc: 0.5042\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 0.7900 - acc: 0.5093\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 0.7530 - acc: 0.5073\n",
      "Epoch 5/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.7268 - acc: 0.5073\n",
      "Epoch 00005: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.7266 - acc: 0.5071\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 0.7138 - acc: 0.5017\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.6992 - acc: 0.5132\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 4s 125ms/step - loss: 0.6971 - acc: 0.5107\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 0.6930 - acc: 0.5244\n",
      "Epoch 10/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6901 - acc: 0.5376\n",
      "Epoch 00010: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 0.6898 - acc: 0.5376\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.6900 - acc: 0.5383\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 5s 144ms/step - loss: 0.6907 - acc: 0.5320\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 4s 131ms/step - loss: 0.6897 - acc: 0.5378\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 5s 148ms/step - loss: 0.6891 - acc: 0.5388\n",
      "Epoch 15/100\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.6891 - acc: 0.5372\n",
      "Epoch 00015: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 0.6892 - acc: 0.5366\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 0.6900 - acc: 0.5361\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 5s 144ms/step - loss: 0.6895 - acc: 0.5444\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 0.6893 - acc: 0.5359\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.6899 - acc: 0.5344\n",
      "Epoch 20/100\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.6890 - acc: 0.5430\n",
      "Epoch 00020: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.6892 - acc: 0.5425\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 0.6890 - acc: 0.5388\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 4s 127ms/step - loss: 0.6887 - acc: 0.5461\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.6888 - acc: 0.5500\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 4s 126ms/step - loss: 0.6898 - acc: 0.5383\n",
      "Epoch 25/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6886 - acc: 0.5502\n",
      "Epoch 00025: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 0.6886 - acc: 0.5498\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 0.6890 - acc: 0.5447\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 0.6892 - acc: 0.5432\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.6890 - acc: 0.5442\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 0.6889 - acc: 0.5413\n",
      "Epoch 30/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6892 - acc: 0.5441\n",
      "Epoch 00030: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.6892 - acc: 0.5439\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 5s 144ms/step - loss: 0.6886 - acc: 0.5454\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 0.6883 - acc: 0.5474\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 0.6892 - acc: 0.5383\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 4s 131ms/step - loss: 0.6887 - acc: 0.5413\n",
      "Epoch 35/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6886 - acc: 0.5484\n",
      "Epoch 00035: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 0.6887 - acc: 0.5471\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 0.6886 - acc: 0.5420\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 0.6890 - acc: 0.5427\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 0.6886 - acc: 0.5413\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 5s 144ms/step - loss: 0.6888 - acc: 0.5425\n",
      "Epoch 40/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6887 - acc: 0.5408\n",
      "Epoch 00040: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 147ms/step - loss: 0.6887 - acc: 0.5403\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 4s 134ms/step - loss: 0.6881 - acc: 0.5481\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 0.6886 - acc: 0.5491\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 4s 124ms/step - loss: 0.6882 - acc: 0.5457\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.6884 - acc: 0.5466\n",
      "Epoch 45/100\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.6880 - acc: 0.5469\n",
      "Epoch 00045: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 0.6881 - acc: 0.5479\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 4s 124ms/step - loss: 0.6884 - acc: 0.5452\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.6884 - acc: 0.5442\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 0.6877 - acc: 0.5537\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.6878 - acc: 0.5542\n",
      "Epoch 50/100\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.6879 - acc: 0.5487\n",
      "Epoch 00050: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 148ms/step - loss: 0.6878 - acc: 0.5483\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.6883 - acc: 0.5474\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.6879 - acc: 0.5474\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.6873 - acc: 0.5498\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 0.6880 - acc: 0.5430\n",
      "Epoch 55/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6874 - acc: 0.5514\n",
      "Epoch 00055: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.6876 - acc: 0.5505\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 5s 148ms/step - loss: 0.6875 - acc: 0.5491\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 4s 126ms/step - loss: 0.6875 - acc: 0.5508\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.6874 - acc: 0.5486\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 0.6870 - acc: 0.5549\n",
      "Epoch 60/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6875 - acc: 0.5479\n",
      "Epoch 00060: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.6874 - acc: 0.5491\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 0.6876 - acc: 0.5396\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 5s 144ms/step - loss: 0.6865 - acc: 0.5620\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.6864 - acc: 0.5581\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 0.6877 - acc: 0.5522\n",
      "Epoch 65/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6858 - acc: 0.5575\n",
      "Epoch 00065: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.6858 - acc: 0.5569\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 0.6871 - acc: 0.5547\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.6856 - acc: 0.5618\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 0.6859 - acc: 0.5535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "32/32 [==============================] - 5s 142ms/step - loss: 0.6854 - acc: 0.5513\n",
      "Epoch 70/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6861 - acc: 0.5532\n",
      "Epoch 00070: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 164ms/step - loss: 0.6861 - acc: 0.5535\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 0.6860 - acc: 0.5591\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 5s 165ms/step - loss: 0.6859 - acc: 0.5542\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.6862 - acc: 0.5557\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.6852 - acc: 0.5623\n",
      "Epoch 75/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6850 - acc: 0.5630\n",
      "Epoch 00075: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 0.6850 - acc: 0.5640\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 0.6852 - acc: 0.5593\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 5s 167ms/step - loss: 0.6841 - acc: 0.5623\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 0.6842 - acc: 0.5652\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 4s 141ms/step - loss: 0.6847 - acc: 0.5591\n",
      "Epoch 80/100\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.6840 - acc: 0.5669\n",
      "Epoch 00080: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.6843 - acc: 0.5654\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 0.6859 - acc: 0.5549\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.6833 - acc: 0.5630\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 5s 145ms/step - loss: 0.6830 - acc: 0.5676\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 0.6830 - acc: 0.5698\n",
      "Epoch 85/100\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.6839 - acc: 0.5612\n",
      "Epoch 00085: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 4s 130ms/step - loss: 0.6841 - acc: 0.5588\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 0.6832 - acc: 0.5652\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 4s 134ms/step - loss: 0.6836 - acc: 0.5542\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 0.6827 - acc: 0.5637 2s - loss\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.6831 - acc: 0.5603\n",
      "Epoch 90/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6825 - acc: 0.5643\n",
      "Epoch 00090: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 166ms/step - loss: 0.6822 - acc: 0.5647\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 4s 131ms/step - loss: 0.6827 - acc: 0.5579\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 0.6817 - acc: 0.5642\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 0.6830 - acc: 0.5557\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 0.6815 - acc: 0.5647\n",
      "Epoch 95/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6815 - acc: 0.5617\n",
      "Epoch 00095: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.6817 - acc: 0.5618\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 4s 128ms/step - loss: 0.6816 - acc: 0.5605\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 0.6819 - acc: 0.5586\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 0.6808 - acc: 0.5649\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 0.6801 - acc: 0.5657\n",
      "Epoch 100/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6807 - acc: 0.5628\n",
      "Epoch 00100: saving model to training/cp.ckpt\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.6810 - acc: 0.5620\n",
      "10/10 [==============================] - 1s 121ms/step - loss: 0.6959 - acc: 0.5123\n",
      "Model, accuracy: 51.23%\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "# ToDo: Train your model and save it as HDF5 file\n",
    "# again, use https://keras.io/models/model/ \n",
    "\n",
    "fileName = \"model.hd5\"\n",
    "\n",
    "model.fit(X_train, y_train, callbacks=[cp_callback], ... )\n",
    "model.evaluate(X_test, Y_test, ...)\n",
    "\n",
    "model.save(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TFLiteConverter in module tensorflow.lite.python.lite:\n",
      "\n",
      "class TFLiteConverter(builtins.object)\n",
      " |  Convert a TensorFlow model into `output_format` using TOCO.\n",
      " |  \n",
      " |  This is used to convert from a TensorFlow GraphDef or SavedModel into either a\n",
      " |  TFLite FlatBuffer or graph visualization.\n",
      " |  \n",
      " |  Attributes:\n",
      " |  \n",
      " |    inference_type: Target data type of real-number arrays in the output file.\n",
      " |      Must be `{tf.float32, tf.uint8}`. (default tf.float32)\n",
      " |    inference_input_type: Target data type of real-number input arrays. Allows\n",
      " |      for a different type for input arrays in the case of quantization.\n",
      " |      Must be `{tf.float32, tf.uint8}`. (default `inference_type`)\n",
      " |    output_format: Output file format. Currently must be `{TFLITE,\n",
      " |      GRAPHVIZ_DOT}`. (default TFLITE)\n",
      " |    quantized_input_stats: Dict of strings representing input tensor names\n",
      " |      mapped to tuple of floats representing the mean and standard deviation\n",
      " |      of the training data (e.g., {\"foo\" : (0., 1.)}). Only need if\n",
      " |      `inference_input_type` is `QUANTIZED_UINT8`.\n",
      " |      real_input_value = (quantized_input_value - mean_value) / std_dev_value.\n",
      " |      (default {})\n",
      " |    default_ranges_stats: Tuple of integers representing (min, max) range values\n",
      " |      for all arrays without a specified range. Intended for experimenting with\n",
      " |      quantization via \"dummy quantization\". (default None)\n",
      " |    drop_control_dependency: Boolean indicating whether to drop control\n",
      " |      dependencies silently. This is due to TFLite not supporting control\n",
      " |      dependencies. (default True)\n",
      " |    reorder_across_fake_quant: Boolean indicating whether to reorder FakeQuant\n",
      " |      nodes in unexpected locations. Used when the location of the FakeQuant\n",
      " |      nodes is preventing graph transformations necessary to convert the graph.\n",
      " |      Results in a graph that differs from the quantized training graph,\n",
      " |      potentially causing differing arithmetic behavior. (default False)\n",
      " |    change_concat_input_ranges: Boolean to change behavior of min/max ranges for\n",
      " |      inputs and outputs of the concat operator for quantized models. Changes\n",
      " |      the ranges of concat operator overlap when true. (default False)\n",
      " |    allow_custom_ops: Boolean indicating whether to allow custom operations.\n",
      " |      When false any unknown operation is an error. When true, custom ops are\n",
      " |      created for any op that is unknown. The developer will need to provide\n",
      " |      these to the TensorFlow Lite runtime with a custom resolver.\n",
      " |      (default False)\n",
      " |    post_training_quantize: Boolean indicating whether to quantize the weights\n",
      " |      of the converted float model. Model size will be reduced and there will be\n",
      " |      latency improvements (at the cost of accuracy).\n",
      " |      (default False)\n",
      " |    dump_graphviz_dir: Full filepath of folder to dump the graphs at various\n",
      " |      stages of processing GraphViz .dot files. Preferred over\n",
      " |      --output_format=GRAPHVIZ_DOT in order to keep the requirements of the\n",
      " |      output file. (default None)\n",
      " |    dump_graphviz_video: Boolean indicating whether to dump the graph after\n",
      " |      every graph transformation. (default False)\n",
      " |    target_ops: Experimental flag, subject to change. Set of OpsSet\n",
      " |      options indicating which converter to use.\n",
      " |      (default set([OpsSet.TFLITE_BUILTINS]))\n",
      " |  \n",
      " |  Example usage:\n",
      " |  \n",
      " |    ```python\n",
      " |    # Converting a GraphDef from session.\n",
      " |    converter = lite.TFLiteConverter.from_session(sess, in_tensors, out_tensors)\n",
      " |    tflite_model = converter.convert()\n",
      " |    open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
      " |  \n",
      " |    # Converting a GraphDef from file.\n",
      " |    converter = lite.TFLiteConverter.from_frozen_graph(\n",
      " |      graph_def_file, input_arrays, output_arrays)\n",
      " |    tflite_model = converter.convert()\n",
      " |    open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
      " |  \n",
      " |    # Converting a SavedModel.\n",
      " |    converter = lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
      " |    tflite_model = converter.convert()\n",
      " |  \n",
      " |    # Converting a tf.keras model.\n",
      " |    converter = lite.TFLiteConverter.from_keras_model_file(keras_model)\n",
      " |    tflite_model = converter.convert()\n",
      " |    ```\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, graph_def, input_tensors, output_tensors, input_arrays_with_shape=None, output_arrays=None)\n",
      " |      Constructor for TFLiteConverter.\n",
      " |      \n",
      " |      Args:\n",
      " |        graph_def: Frozen TensorFlow GraphDef.\n",
      " |        input_tensors: List of input tensors. Type and shape are computed using\n",
      " |          `foo.get_shape()` and `foo.dtype`.\n",
      " |        output_tensors: List of output tensors (only .name is used from this).\n",
      " |        input_arrays_with_shape: Tuple of strings representing input tensor names\n",
      " |          and list of integers representing input shapes\n",
      " |          (e.g., [(\"foo\" : [1, 16, 16, 3])]). Use only when graph cannot be loaded\n",
      " |            into TensorFlow and when `input_tensors` and `output_tensors` are\n",
      " |            None. (default None)\n",
      " |        output_arrays: List of output tensors to freeze graph with. Use only when\n",
      " |          graph cannot be loaded into TensorFlow and when `input_tensors` and\n",
      " |          `output_tensors` are None. (default None)\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: Invalid arguments.\n",
      " |  \n",
      " |  convert(self)\n",
      " |      Converts a TensorFlow GraphDef based on instance variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The converted data in serialized format. Either a TFLite Flatbuffer or a\n",
      " |        Graphviz graph depending on value in `output_format`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          Input shape is not specified.\n",
      " |          None value for dimension in input_tensor.\n",
      " |  \n",
      " |  get_input_arrays(self)\n",
      " |      Returns a list of the names of the input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of strings.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shapes=None) from builtins.type\n",
      " |      Creates a TFLiteConverter class from a file containing a frozen GraphDef.\n",
      " |      \n",
      " |      Args:\n",
      " |        graph_def_file: Full filepath of file containing frozen GraphDef.\n",
      " |        input_arrays: List of input tensors to freeze graph with.\n",
      " |        output_arrays: List of output tensors to freeze graph with.\n",
      " |        input_shapes: Dict of strings representing input tensor names to list of\n",
      " |          integers representing input shapes (e.g., {\"foo\" : [1, 16, 16, 3]}).\n",
      " |          Automatically determined when input shapes is None (e.g., {\"foo\" :\n",
      " |            None}). (default None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        TFLiteConverter class.\n",
      " |      \n",
      " |      Raises:\n",
      " |        IOError:\n",
      " |          File not found.\n",
      " |          Unable to parse input file.\n",
      " |        ValueError:\n",
      " |          The graph is not frozen.\n",
      " |          input_arrays or output_arrays contains an invalid tensor name.\n",
      " |          input_shapes is not correctly defined when required\n",
      " |  \n",
      " |  from_keras_model_file(model_file, input_arrays=None, input_shapes=None, output_arrays=None) from builtins.type\n",
      " |      Creates a TFLiteConverter class from a tf.keras model file.\n",
      " |      \n",
      " |      Args:\n",
      " |        model_file: Full filepath of HDF5 file containing the tf.keras model.\n",
      " |        input_arrays: List of input tensors to freeze graph with. Uses input\n",
      " |          arrays from SignatureDef when none are provided. (default None)\n",
      " |        input_shapes: Dict of strings representing input tensor names to list of\n",
      " |          integers representing input shapes (e.g., {\"foo\" : [1, 16, 16, 3]}).\n",
      " |          Automatically determined when input shapes is None (e.g., {\"foo\" :\n",
      " |            None}). (default None)\n",
      " |        output_arrays: List of output tensors to freeze graph with. Uses output\n",
      " |          arrays from SignatureDef when none are provided. (default None)\n",
      " |      \n",
      " |      Returns:\n",
      " |        TFLiteConverter class.\n",
      " |  \n",
      " |  from_saved_model(saved_model_dir, input_arrays=None, input_shapes=None, output_arrays=None, tag_set=None, signature_key=None) from builtins.type\n",
      " |      Creates a TFLiteConverter class from a SavedModel.\n",
      " |      \n",
      " |      Args:\n",
      " |        saved_model_dir: SavedModel directory to convert.\n",
      " |        input_arrays: List of input tensors to freeze graph with. Uses input\n",
      " |          arrays from SignatureDef when none are provided. (default None)\n",
      " |        input_shapes: Dict of strings representing input tensor names to list of\n",
      " |          integers representing input shapes (e.g., {\"foo\" : [1, 16, 16, 3]}).\n",
      " |          Automatically determined when input shapes is None (e.g., {\"foo\" :\n",
      " |            None}). (default None)\n",
      " |        output_arrays: List of output tensors to freeze graph with. Uses output\n",
      " |          arrays from SignatureDef when none are provided. (default None)\n",
      " |        tag_set: Set of tags identifying the MetaGraphDef within the SavedModel to\n",
      " |          analyze. All tags in the tag set must be present. (default set(\"serve\"))\n",
      " |        signature_key: Key identifying SignatureDef containing inputs and outputs.\n",
      " |          (default DEFAULT_SERVING_SIGNATURE_DEF_KEY)\n",
      " |      \n",
      " |      Returns:\n",
      " |        TFLiteConverter class.\n",
      " |  \n",
      " |  from_session(sess, input_tensors, output_tensors) from builtins.type\n",
      " |      Creates a TFLiteConverter class from a TensorFlow Session.\n",
      " |      \n",
      " |      Args:\n",
      " |        sess: TensorFlow Session.\n",
      " |        input_tensors: List of input tensors. Type and shape are computed using\n",
      " |          `foo.get_shape()` and `foo.dtype`.\n",
      " |        output_tensors: List of output tensors (only .name is used from this).\n",
      " |      \n",
      " |      Returns:\n",
      " |        TFLiteConverter class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this command for detailed documentation on the attributes of tflite-convert.\n",
    "help(tf.lite.TFLiteConverter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py:591: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1984"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ToDo: Convert to TensorFlow Lite model and save.\n",
    "converter = \n",
    "tflite_model = \n",
    "open(\"graph.tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
